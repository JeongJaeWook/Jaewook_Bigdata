{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기 및 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "#전처리 및 데이터 split\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/traindata_google_appstore.xlsm',usecols='B,C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5줄만 보기]\n",
      "label 1 : 불량  | 0 : 정상 | 3 : 모름,기억안남,없음\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>C1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ㅣㅣㅣㅣ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ㅠㅡㄹ레이스토어</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ㅜ글스토어</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ㅓㅄ음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>히어로 스카이</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label        C1\n",
       "0      1      ㅣㅣㅣㅣ\n",
       "1      1  ㅠㅡㄹ레이스토어\n",
       "2      1     ㅜ글스토어\n",
       "3      1       ㅓㅄ음\n",
       "4      0   히어로 스카이"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[데이터 속성]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47581 entries, 0 to 47580\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   47581 non-null  int64 \n",
      " 1   C1      47581 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 743.6+ KB\n",
      "None\n",
      "\n",
      "[데이터 label 갯수]\n",
      "0    45908\n",
      "3     1202\n",
      "1      471\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df.columns = ['label','C1'] #열 이름 변경\n",
    "print(\"\\n[5줄만 보기]\")\n",
    "print(\"label 1 : 불량  | 0 : 정상 | 3 : 모름,기억안남,없음\")\n",
    "display(df.head(5))\n",
    "\n",
    "print(\"\\n[데이터 속성]\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n[데이터 label 갯수]\")\n",
    "print(df['label'].value_counts())\n",
    "#학습할 불량샘플이 너무 작은게 아닐까..?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리\n",
    "클리닝 -> 함수화\n",
    "\n",
    "**모름, 기억나지않음 등과 같은 경우는 어떤 경우엔 정상 샘플로 넘기기 때문에 label을 3으로 표시**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#클리닝 함수\n",
    "def cleanText(text):\n",
    "    repl =''\n",
    "       \n",
    "    if text.isdecimal() : #숫자로만 구성되어 있을 때 공백 치환\n",
    "        text = ''\n",
    "    \n",
    "    text = text.lower() #영어일경우 소문자로 변경\n",
    "    text = text.strip().replace('\\\\','')# 기호 치환\n",
    "    \n",
    "    pattern = '([ㄱ-ㅎㅏ-ㅣ]+)' # 자음, 모음 제거\n",
    "    text = re.sub(pattern= pattern, repl=repl, string=text)\n",
    "          \n",
    "    pattern = '[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]' # 특수기호 제거\n",
    "    text = re.sub(pattern= pattern, repl=repl, string=text)\n",
    "    \n",
    "    if len(text)==0 :\n",
    "        text = '불량'\n",
    "    #text = text.replace(' ','불량')# 모든 공백 제거 이건 아닌것 같아서 삭제\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인자로 입력받은 DataFrame을 복사 한 뒤 C1 컬럼 문자형 변환하고 복사된 DataFrame 반환\n",
    "def get_preprocessed_df(df=None):\n",
    "    df_copy = df.copy()\n",
    "    df_copy.columns = ['label','C1'] #열 이름 변경\n",
    "           \n",
    "    #1. 응답에 숫자도 있어서 int 형으로 처리됌 -> 문자형으로 변환\n",
    "    df_text = df_copy['C1'].apply(str)   \n",
    "       \n",
    "    #2. 텍스트 클리닝 (자음/모음/숫자만으로 이루어진 경우 빈칸처리, 특수기호 제거)\n",
    "    df_text = df_text.map(lambda x: cleanText(x))\n",
    "    \n",
    "    #3.. 더 있나?\n",
    "        \n",
    "    #마지막에 다시 대입\n",
    "    df_copy['C1'] = df_text\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>C1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>불량</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>레이스토어</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>글스토어</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>히어로 스카이</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47576</th>\n",
       "      <td>1</td>\n",
       "      <td>불량</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47577</th>\n",
       "      <td>1</td>\n",
       "      <td>불량</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47578</th>\n",
       "      <td>1</td>\n",
       "      <td>불량</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47579</th>\n",
       "      <td>1</td>\n",
       "      <td>불량</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47580</th>\n",
       "      <td>1</td>\n",
       "      <td>불량</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47581 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label       C1\n",
       "0          1       불량\n",
       "1          1    레이스토어\n",
       "2          1     글스토어\n",
       "3          1        음\n",
       "4          0  히어로 스카이\n",
       "...      ...      ...\n",
       "47576      1       불량\n",
       "47577      1       불량\n",
       "47578      1       불량\n",
       "47579      1       불량\n",
       "47580      1       불량\n",
       "\n",
       "[47581 rows x 2 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy = get_preprocessed_df(df)\n",
    "# df_copy.isnull().sum() #공백은 불량으로 처리..?\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 임베딩\n",
    "-단어 수준 임베딩\n",
    "\n",
    "    Latent Semantic Analysis\n",
    "    Word2Vec\n",
    "    GloVe\n",
    "    FastText\n",
    "    Swivel\n",
    "    \n",
    "-문장 수준 임베딩\n",
    "\n",
    "    Weighted Embeddings\n",
    "    Latent Semantic Analysis\n",
    "    Latent Dirichlet Allocation\n",
    "    Doc2Vec\n",
    "    Embeddings from Language Models (ELMo)\n",
    "    Bidirectional Encoder Representations from Transformer (BERT)\n",
    "    \n",
    "    \n",
    "출처 : https://github.com/ratsgo/embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>C1</th>\n",
       "      <th>X_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>불량</td>\n",
       "      <td>(0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>레이스토어</td>\n",
       "      <td>(0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>글스토어</td>\n",
       "      <td>(0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>음</td>\n",
       "      <td>(0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>히어로 스카이</td>\n",
       "      <td>(0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47576</th>\n",
       "      <td>1</td>\n",
       "      <td>불량</td>\n",
       "      <td>(0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47577</th>\n",
       "      <td>1</td>\n",
       "      <td>불량</td>\n",
       "      <td>(0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47578</th>\n",
       "      <td>1</td>\n",
       "      <td>불량</td>\n",
       "      <td>(0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47579</th>\n",
       "      <td>1</td>\n",
       "      <td>불량</td>\n",
       "      <td>(0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47580</th>\n",
       "      <td>1</td>\n",
       "      <td>불량</td>\n",
       "      <td>(0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47581 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label       C1                                         X_features\n",
       "0          1       불량    (0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...\n",
       "1          1    레이스토어    (0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...\n",
       "2          1     글스토어    (0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...\n",
       "3          1        음    (0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...\n",
       "4          0  히어로 스카이    (0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...\n",
       "...      ...      ...                                                ...\n",
       "47576      1       불량    (0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...\n",
       "47577      1       불량    (0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...\n",
       "47578      1       불량    (0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...\n",
       "47579      1       불량    (0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...\n",
       "47580      1       불량    (0, 1185)\\t1.0\\n  (1, 934)\\t1.0\\n  (2, 717)\\...\n",
       "\n",
       "[47581 rows x 3 columns]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#벡터화\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_features = vectorizer.fit_transform(df_copy['C1'].copy())\n",
    "df_copy['X_features'] = X_features\n",
    "y_target = df_copy['label'].copy()\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.2, random_state=333,stratify=y_target )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =X_features\n",
    "X_test = X_features\n",
    "\n",
    "y_train =y_target\n",
    "y_test = y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_logloss: 0.0963368\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's multi_logloss: 0.0892729\n",
      "[3]\ttraining's multi_logloss: 0.0841041\n",
      "[4]\ttraining's multi_logloss: 0.0798861\n",
      "[5]\ttraining's multi_logloss: 0.0763638\n",
      "[6]\ttraining's multi_logloss: 0.0733774\n",
      "[7]\ttraining's multi_logloss: 0.0708301\n",
      "[8]\ttraining's multi_logloss: 0.0686303\n",
      "[9]\ttraining's multi_logloss: 0.0667258\n",
      "[10]\ttraining's multi_logloss: 0.0650585\n",
      "[11]\ttraining's multi_logloss: 0.063596\n",
      "[12]\ttraining's multi_logloss: 0.0623044\n",
      "[13]\ttraining's multi_logloss: 0.0611617\n",
      "[14]\ttraining's multi_logloss: 0.0601477\n",
      "[15]\ttraining's multi_logloss: 0.0592418\n",
      "[16]\ttraining's multi_logloss: 0.0584318\n",
      "[17]\ttraining's multi_logloss: 0.0577061\n",
      "[18]\ttraining's multi_logloss: 0.0570529\n",
      "[19]\ttraining's multi_logloss: 0.0564575\n",
      "[20]\ttraining's multi_logloss: 0.0559189\n",
      "[21]\ttraining's multi_logloss: 0.0554312\n",
      "[22]\ttraining's multi_logloss: 0.0549846\n",
      "[23]\ttraining's multi_logloss: 0.0545747\n",
      "[24]\ttraining's multi_logloss: 0.0542011\n",
      "[25]\ttraining's multi_logloss: 0.0538526\n",
      "[26]\ttraining's multi_logloss: 0.053531\n",
      "[27]\ttraining's multi_logloss: 0.0532333\n",
      "[28]\ttraining's multi_logloss: 0.0529551\n",
      "[29]\ttraining's multi_logloss: 0.0526967\n",
      "[30]\ttraining's multi_logloss: 0.0524523\n",
      "[31]\ttraining's multi_logloss: 0.0522232\n",
      "[32]\ttraining's multi_logloss: 0.0520062\n",
      "[33]\ttraining's multi_logloss: 0.0518016\n",
      "[34]\ttraining's multi_logloss: 0.0516085\n",
      "[35]\ttraining's multi_logloss: 0.0514245\n",
      "[36]\ttraining's multi_logloss: 0.0512488\n",
      "[37]\ttraining's multi_logloss: 0.0510824\n",
      "[38]\ttraining's multi_logloss: 0.0509233\n",
      "[39]\ttraining's multi_logloss: 0.0507713\n",
      "[40]\ttraining's multi_logloss: 0.0506268\n",
      "[41]\ttraining's multi_logloss: 0.0504875\n",
      "[42]\ttraining's multi_logloss: 0.0503541\n",
      "[43]\ttraining's multi_logloss: 0.0502265\n",
      "[44]\ttraining's multi_logloss: 0.0501053\n",
      "[45]\ttraining's multi_logloss: 0.0499883\n",
      "[46]\ttraining's multi_logloss: 0.0498767\n",
      "[47]\ttraining's multi_logloss: 0.0497693\n",
      "[48]\ttraining's multi_logloss: 0.0496667\n",
      "[49]\ttraining's multi_logloss: 0.0495683\n",
      "[50]\ttraining's multi_logloss: 0.0494687\n",
      "[51]\ttraining's multi_logloss: 0.0493749\n",
      "[52]\ttraining's multi_logloss: 0.0492888\n",
      "[53]\ttraining's multi_logloss: 0.0492032\n",
      "[54]\ttraining's multi_logloss: 0.049123\n",
      "[55]\ttraining's multi_logloss: 0.0490455\n",
      "[56]\ttraining's multi_logloss: 0.0489711\n",
      "[57]\ttraining's multi_logloss: 0.0489005\n",
      "[58]\ttraining's multi_logloss: 0.0488322\n",
      "[59]\ttraining's multi_logloss: 0.0487417\n",
      "[60]\ttraining's multi_logloss: 0.0486758\n",
      "[61]\ttraining's multi_logloss: 0.0486063\n",
      "[62]\ttraining's multi_logloss: 0.0485471\n",
      "[63]\ttraining's multi_logloss: 0.0484855\n",
      "[64]\ttraining's multi_logloss: 0.0484315\n",
      "[65]\ttraining's multi_logloss: 0.0483766\n",
      "[66]\ttraining's multi_logloss: 0.0483272\n",
      "[67]\ttraining's multi_logloss: 0.0482784\n",
      "[68]\ttraining's multi_logloss: 0.0482311\n",
      "[69]\ttraining's multi_logloss: 0.0481882\n",
      "[70]\ttraining's multi_logloss: 0.0481456\n",
      "[71]\ttraining's multi_logloss: 0.04811\n",
      "[72]\ttraining's multi_logloss: 0.0480745\n",
      "[73]\ttraining's multi_logloss: 0.0480401\n",
      "[74]\ttraining's multi_logloss: 0.048002\n",
      "[75]\ttraining's multi_logloss: 0.0479702\n",
      "[76]\ttraining's multi_logloss: 0.0479372\n",
      "[77]\ttraining's multi_logloss: 0.0479097\n",
      "[78]\ttraining's multi_logloss: 0.0478825\n",
      "[79]\ttraining's multi_logloss: 0.047858\n",
      "[80]\ttraining's multi_logloss: 0.0478329\n",
      "[81]\ttraining's multi_logloss: 0.0478107\n",
      "[82]\ttraining's multi_logloss: 0.0477978\n",
      "[83]\ttraining's multi_logloss: 0.0477761\n",
      "[84]\ttraining's multi_logloss: 0.047756\n",
      "[85]\ttraining's multi_logloss: 0.0477363\n",
      "[86]\ttraining's multi_logloss: 0.047719\n",
      "[87]\ttraining's multi_logloss: 0.0477016\n",
      "[88]\ttraining's multi_logloss: 0.0476887\n",
      "[89]\ttraining's multi_logloss: 0.0476745\n",
      "[90]\ttraining's multi_logloss: 0.0476582\n",
      "[91]\ttraining's multi_logloss: 0.0476471\n",
      "[92]\ttraining's multi_logloss: 0.0476352\n",
      "[93]\ttraining's multi_logloss: 0.0476229\n",
      "[94]\ttraining's multi_logloss: 0.0476118\n",
      "[95]\ttraining's multi_logloss: 0.0476003\n",
      "[96]\ttraining's multi_logloss: 0.0475958\n",
      "[97]\ttraining's multi_logloss: 0.0475932\n",
      "[98]\ttraining's multi_logloss: 0.0475887\n",
      "[99]\ttraining's multi_logloss: 0.0475866\n",
      "[100]\ttraining's multi_logloss: 0.0475825\n",
      "[101]\ttraining's multi_logloss: 0.0475786\n",
      "[102]\ttraining's multi_logloss: 0.0475745\n",
      "[103]\ttraining's multi_logloss: 0.0475738\n",
      "[104]\ttraining's multi_logloss: 0.0475714\n",
      "[105]\ttraining's multi_logloss: 0.0475693\n",
      "[106]\ttraining's multi_logloss: 0.0475669\n",
      "[107]\ttraining's multi_logloss: 0.0475655\n",
      "[108]\ttraining's multi_logloss: 0.0475631\n",
      "[109]\ttraining's multi_logloss: 0.0475622\n",
      "[110]\ttraining's multi_logloss: 0.0475609\n",
      "[111]\ttraining's multi_logloss: 0.04756\n",
      "[112]\ttraining's multi_logloss: 0.0475592\n",
      "[113]\ttraining's multi_logloss: 0.0475585\n",
      "[114]\ttraining's multi_logloss: 0.0475579\n",
      "[115]\ttraining's multi_logloss: 0.0475574\n",
      "[116]\ttraining's multi_logloss: 0.0475571\n",
      "[117]\ttraining's multi_logloss: 0.0475568\n",
      "[118]\ttraining's multi_logloss: 0.0475566\n",
      "[119]\ttraining's multi_logloss: 0.0475562\n",
      "[120]\ttraining's multi_logloss: 0.0475562\n",
      "[121]\ttraining's multi_logloss: 0.0475561\n",
      "[122]\ttraining's multi_logloss: 0.047556\n",
      "[123]\ttraining's multi_logloss: 0.0475559\n",
      "[124]\ttraining's multi_logloss: 0.0475558\n",
      "[125]\ttraining's multi_logloss: 0.0475556\n",
      "[126]\ttraining's multi_logloss: 0.0475555\n",
      "[127]\ttraining's multi_logloss: 0.0475553\n",
      "[128]\ttraining's multi_logloss: 0.0475552\n",
      "[129]\ttraining's multi_logloss: 0.0475552\n",
      "[130]\ttraining's multi_logloss: 0.0475551\n",
      "[131]\ttraining's multi_logloss: 0.047555\n",
      "[132]\ttraining's multi_logloss: 0.047555\n",
      "[133]\ttraining's multi_logloss: 0.0475549\n",
      "[134]\ttraining's multi_logloss: 0.0475547\n",
      "[135]\ttraining's multi_logloss: 0.0475546\n",
      "[136]\ttraining's multi_logloss: 0.0475546\n",
      "[137]\ttraining's multi_logloss: 0.0475545\n",
      "[138]\ttraining's multi_logloss: 0.0475544\n",
      "[139]\ttraining's multi_logloss: 0.0475544\n",
      "[140]\ttraining's multi_logloss: 0.0475543\n",
      "[141]\ttraining's multi_logloss: 0.0475543\n",
      "[142]\ttraining's multi_logloss: 0.0475542\n",
      "[143]\ttraining's multi_logloss: 0.0475542\n",
      "[144]\ttraining's multi_logloss: 0.0475541\n",
      "[145]\ttraining's multi_logloss: 0.0475541\n",
      "[146]\ttraining's multi_logloss: 0.047554\n",
      "[147]\ttraining's multi_logloss: 0.047554\n",
      "[148]\ttraining's multi_logloss: 0.0475539\n",
      "[149]\ttraining's multi_logloss: 0.0475539\n",
      "[150]\ttraining's multi_logloss: 0.0475538\n",
      "[151]\ttraining's multi_logloss: 0.0475538\n",
      "[152]\ttraining's multi_logloss: 0.0475537\n",
      "[153]\ttraining's multi_logloss: 0.0475537\n",
      "[154]\ttraining's multi_logloss: 0.0475536\n",
      "[155]\ttraining's multi_logloss: 0.0475536\n",
      "[156]\ttraining's multi_logloss: 0.0475536\n",
      "[157]\ttraining's multi_logloss: 0.0475535\n",
      "[158]\ttraining's multi_logloss: 0.0475535\n",
      "[159]\ttraining's multi_logloss: 0.0475534\n",
      "[160]\ttraining's multi_logloss: 0.0475534\n",
      "[161]\ttraining's multi_logloss: 0.0475533\n",
      "[162]\ttraining's multi_logloss: 0.0475533\n",
      "[163]\ttraining's multi_logloss: 0.0475533\n",
      "[164]\ttraining's multi_logloss: 0.0475532\n",
      "[165]\ttraining's multi_logloss: 0.0475532\n",
      "[166]\ttraining's multi_logloss: 0.0475531\n",
      "[167]\ttraining's multi_logloss: 0.0475531\n",
      "[168]\ttraining's multi_logloss: 0.0475531\n",
      "[169]\ttraining's multi_logloss: 0.0475528\n",
      "[170]\ttraining's multi_logloss: 0.0475528\n",
      "[171]\ttraining's multi_logloss: 0.0475527\n",
      "[172]\ttraining's multi_logloss: 0.0475527\n",
      "[173]\ttraining's multi_logloss: 0.0475527\n",
      "[174]\ttraining's multi_logloss: 0.0475526\n",
      "[175]\ttraining's multi_logloss: 0.0475526\n",
      "[176]\ttraining's multi_logloss: 0.0475526\n",
      "[177]\ttraining's multi_logloss: 0.0475525\n",
      "[178]\ttraining's multi_logloss: 0.0475525\n",
      "[179]\ttraining's multi_logloss: 0.0475524\n",
      "[180]\ttraining's multi_logloss: 0.0475524\n",
      "[181]\ttraining's multi_logloss: 0.0475522\n",
      "[182]\ttraining's multi_logloss: 0.0475522\n",
      "[183]\ttraining's multi_logloss: 0.0475522\n",
      "[184]\ttraining's multi_logloss: 0.0475521\n",
      "[185]\ttraining's multi_logloss: 0.0475521\n",
      "[186]\ttraining's multi_logloss: 0.0475521\n",
      "[187]\ttraining's multi_logloss: 0.047552\n",
      "[188]\ttraining's multi_logloss: 0.047552\n",
      "[189]\ttraining's multi_logloss: 0.047552\n",
      "[190]\ttraining's multi_logloss: 0.0475519\n",
      "[191]\ttraining's multi_logloss: 0.0475519\n",
      "[192]\ttraining's multi_logloss: 0.0475519\n",
      "[193]\ttraining's multi_logloss: 0.0475518\n",
      "[194]\ttraining's multi_logloss: 0.0475518\n",
      "[195]\ttraining's multi_logloss: 0.0475518\n",
      "[196]\ttraining's multi_logloss: 0.0475517\n",
      "[197]\ttraining's multi_logloss: 0.0475517\n",
      "[198]\ttraining's multi_logloss: 0.0475517\n",
      "[199]\ttraining's multi_logloss: 0.0475516\n",
      "[200]\ttraining's multi_logloss: 0.0475516\n",
      "[201]\ttraining's multi_logloss: 0.0475516\n",
      "[202]\ttraining's multi_logloss: 0.0475516\n",
      "[203]\ttraining's multi_logloss: 0.0475515\n",
      "[204]\ttraining's multi_logloss: 0.0475515\n",
      "[205]\ttraining's multi_logloss: 0.0475515\n",
      "[206]\ttraining's multi_logloss: 0.0475514\n",
      "[207]\ttraining's multi_logloss: 0.0475514\n",
      "[208]\ttraining's multi_logloss: 0.0475514\n",
      "[209]\ttraining's multi_logloss: 0.0475514\n",
      "[210]\ttraining's multi_logloss: 0.0475513\n",
      "[211]\ttraining's multi_logloss: 0.0475513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[212]\ttraining's multi_logloss: 0.0475513\n",
      "[213]\ttraining's multi_logloss: 0.0475512\n",
      "[214]\ttraining's multi_logloss: 0.0475512\n",
      "[215]\ttraining's multi_logloss: 0.0475512\n",
      "[216]\ttraining's multi_logloss: 0.0475512\n",
      "[217]\ttraining's multi_logloss: 0.0475511\n",
      "[218]\ttraining's multi_logloss: 0.0475511\n",
      "[219]\ttraining's multi_logloss: 0.0475511\n",
      "[220]\ttraining's multi_logloss: 0.0475511\n",
      "[221]\ttraining's multi_logloss: 0.047551\n",
      "[222]\ttraining's multi_logloss: 0.047551\n",
      "[223]\ttraining's multi_logloss: 0.047551\n",
      "[224]\ttraining's multi_logloss: 0.0475509\n",
      "[225]\ttraining's multi_logloss: 0.0475509\n",
      "[226]\ttraining's multi_logloss: 0.0475509\n",
      "[227]\ttraining's multi_logloss: 0.0475509\n",
      "[228]\ttraining's multi_logloss: 0.0475508\n",
      "[229]\ttraining's multi_logloss: 0.0475508\n",
      "[230]\ttraining's multi_logloss: 0.0475508\n",
      "[231]\ttraining's multi_logloss: 0.0475508\n",
      "[232]\ttraining's multi_logloss: 0.0475507\n",
      "[233]\ttraining's multi_logloss: 0.0475507\n",
      "[234]\ttraining's multi_logloss: 0.0475507\n",
      "[235]\ttraining's multi_logloss: 0.0475507\n",
      "[236]\ttraining's multi_logloss: 0.0475507\n",
      "[237]\ttraining's multi_logloss: 0.0475506\n",
      "[238]\ttraining's multi_logloss: 0.0475506\n",
      "[239]\ttraining's multi_logloss: 0.0475506\n",
      "[240]\ttraining's multi_logloss: 0.0475506\n",
      "[241]\ttraining's multi_logloss: 0.0475505\n",
      "[242]\ttraining's multi_logloss: 0.0475505\n",
      "[243]\ttraining's multi_logloss: 0.0475505\n",
      "[244]\ttraining's multi_logloss: 0.0475505\n",
      "[245]\ttraining's multi_logloss: 0.0475504\n",
      "[246]\ttraining's multi_logloss: 0.0475504\n",
      "[247]\ttraining's multi_logloss: 0.0475504\n",
      "[248]\ttraining's multi_logloss: 0.0475504\n",
      "[249]\ttraining's multi_logloss: 0.0475504\n",
      "[250]\ttraining's multi_logloss: 0.0475503\n",
      "[251]\ttraining's multi_logloss: 0.0475503\n",
      "[252]\ttraining's multi_logloss: 0.0475503\n",
      "[253]\ttraining's multi_logloss: 0.0475503\n",
      "[254]\ttraining's multi_logloss: 0.0475502\n",
      "[255]\ttraining's multi_logloss: 0.0475502\n",
      "[256]\ttraining's multi_logloss: 0.0475502\n",
      "[257]\ttraining's multi_logloss: 0.0475502\n",
      "[258]\ttraining's multi_logloss: 0.0475502\n",
      "[259]\ttraining's multi_logloss: 0.0475501\n",
      "[260]\ttraining's multi_logloss: 0.0475501\n",
      "[261]\ttraining's multi_logloss: 0.0475501\n",
      "[262]\ttraining's multi_logloss: 0.0475501\n",
      "[263]\ttraining's multi_logloss: 0.0475501\n",
      "[264]\ttraining's multi_logloss: 0.04755\n",
      "[265]\ttraining's multi_logloss: 0.04755\n",
      "[266]\ttraining's multi_logloss: 0.04755\n",
      "[267]\ttraining's multi_logloss: 0.04755\n",
      "[268]\ttraining's multi_logloss: 0.04755\n",
      "[269]\ttraining's multi_logloss: 0.0475499\n",
      "[270]\ttraining's multi_logloss: 0.0475499\n",
      "[271]\ttraining's multi_logloss: 0.0475499\n",
      "[272]\ttraining's multi_logloss: 0.0475499\n",
      "[273]\ttraining's multi_logloss: 0.0475499\n",
      "[274]\ttraining's multi_logloss: 0.0475498\n",
      "[275]\ttraining's multi_logloss: 0.0475498\n",
      "[276]\ttraining's multi_logloss: 0.0475498\n",
      "[277]\ttraining's multi_logloss: 0.0475498\n",
      "[278]\ttraining's multi_logloss: 0.0475498\n",
      "[279]\ttraining's multi_logloss: 0.0475498\n",
      "[280]\ttraining's multi_logloss: 0.0475497\n",
      "[281]\ttraining's multi_logloss: 0.0475497\n",
      "[282]\ttraining's multi_logloss: 0.0475497\n",
      "[283]\ttraining's multi_logloss: 0.0475497\n",
      "[284]\ttraining's multi_logloss: 0.0475497\n",
      "[285]\ttraining's multi_logloss: 0.0475496\n",
      "[286]\ttraining's multi_logloss: 0.0475496\n",
      "[287]\ttraining's multi_logloss: 0.0475496\n",
      "[288]\ttraining's multi_logloss: 0.0475496\n",
      "[289]\ttraining's multi_logloss: 0.0475496\n",
      "[290]\ttraining's multi_logloss: 0.0475496\n",
      "[291]\ttraining's multi_logloss: 0.0475495\n",
      "[292]\ttraining's multi_logloss: 0.0475495\n",
      "[293]\ttraining's multi_logloss: 0.0475495\n",
      "[294]\ttraining's multi_logloss: 0.0475495\n",
      "[295]\ttraining's multi_logloss: 0.0475495\n",
      "[296]\ttraining's multi_logloss: 0.0475494\n",
      "[297]\ttraining's multi_logloss: 0.0475494\n",
      "[298]\ttraining's multi_logloss: 0.0475494\n",
      "[299]\ttraining's multi_logloss: 0.0475494\n",
      "[300]\ttraining's multi_logloss: 0.0475494\n",
      "[301]\ttraining's multi_logloss: 0.0475494\n",
      "[302]\ttraining's multi_logloss: 0.0475493\n",
      "[303]\ttraining's multi_logloss: 0.0475493\n",
      "[304]\ttraining's multi_logloss: 0.0475493\n",
      "[305]\ttraining's multi_logloss: 0.0475493\n",
      "[306]\ttraining's multi_logloss: 0.0475493\n",
      "[307]\ttraining's multi_logloss: 0.0475493\n",
      "[308]\ttraining's multi_logloss: 0.0475493\n",
      "[309]\ttraining's multi_logloss: 0.0475492\n",
      "[310]\ttraining's multi_logloss: 0.0475492\n",
      "[311]\ttraining's multi_logloss: 0.0475492\n",
      "[312]\ttraining's multi_logloss: 0.0475492\n",
      "[313]\ttraining's multi_logloss: 0.0475492\n",
      "[314]\ttraining's multi_logloss: 0.0475492\n",
      "[315]\ttraining's multi_logloss: 0.0475491\n",
      "[316]\ttraining's multi_logloss: 0.0475491\n",
      "[317]\ttraining's multi_logloss: 0.0475491\n",
      "[318]\ttraining's multi_logloss: 0.0475491\n",
      "[319]\ttraining's multi_logloss: 0.0475491\n",
      "[320]\ttraining's multi_logloss: 0.0475491\n",
      "[321]\ttraining's multi_logloss: 0.047549\n",
      "[322]\ttraining's multi_logloss: 0.047549\n",
      "[323]\ttraining's multi_logloss: 0.047549\n",
      "[324]\ttraining's multi_logloss: 0.047549\n",
      "[325]\ttraining's multi_logloss: 0.047549\n",
      "[326]\ttraining's multi_logloss: 0.047549\n",
      "[327]\ttraining's multi_logloss: 0.047549\n",
      "[328]\ttraining's multi_logloss: 0.0475489\n",
      "[329]\ttraining's multi_logloss: 0.0475489\n",
      "[330]\ttraining's multi_logloss: 0.0475489\n",
      "[331]\ttraining's multi_logloss: 0.0475489\n",
      "[332]\ttraining's multi_logloss: 0.0475489\n",
      "[333]\ttraining's multi_logloss: 0.0475489\n",
      "[334]\ttraining's multi_logloss: 0.0475489\n",
      "[335]\ttraining's multi_logloss: 0.0475488\n",
      "[336]\ttraining's multi_logloss: 0.0475488\n",
      "[337]\ttraining's multi_logloss: 0.0475488\n",
      "[338]\ttraining's multi_logloss: 0.0475488\n",
      "[339]\ttraining's multi_logloss: 0.0475488\n",
      "[340]\ttraining's multi_logloss: 0.0475488\n",
      "[341]\ttraining's multi_logloss: 0.0475488\n",
      "[342]\ttraining's multi_logloss: 0.0475487\n",
      "[343]\ttraining's multi_logloss: 0.0475487\n",
      "[344]\ttraining's multi_logloss: 0.0475487\n",
      "[345]\ttraining's multi_logloss: 0.0475487\n",
      "[346]\ttraining's multi_logloss: 0.0475487\n",
      "[347]\ttraining's multi_logloss: 0.0475487\n",
      "[348]\ttraining's multi_logloss: 0.0475487\n",
      "[349]\ttraining's multi_logloss: 0.0475486\n",
      "[350]\ttraining's multi_logloss: 0.0475486\n",
      "[351]\ttraining's multi_logloss: 0.0475486\n",
      "[352]\ttraining's multi_logloss: 0.0475486\n",
      "[353]\ttraining's multi_logloss: 0.0475486\n",
      "[354]\ttraining's multi_logloss: 0.0475486\n",
      "[355]\ttraining's multi_logloss: 0.0475486\n",
      "[356]\ttraining's multi_logloss: 0.0475486\n",
      "[357]\ttraining's multi_logloss: 0.0475485\n",
      "[358]\ttraining's multi_logloss: 0.0475485\n",
      "[359]\ttraining's multi_logloss: 0.0475485\n",
      "[360]\ttraining's multi_logloss: 0.0475485\n",
      "[361]\ttraining's multi_logloss: 0.0475485\n",
      "[362]\ttraining's multi_logloss: 0.0475485\n",
      "[363]\ttraining's multi_logloss: 0.0475485\n",
      "[364]\ttraining's multi_logloss: 0.0475485\n",
      "[365]\ttraining's multi_logloss: 0.0475484\n",
      "[366]\ttraining's multi_logloss: 0.0475484\n",
      "[367]\ttraining's multi_logloss: 0.0475484\n",
      "[368]\ttraining's multi_logloss: 0.0475484\n",
      "[369]\ttraining's multi_logloss: 0.0475484\n",
      "[370]\ttraining's multi_logloss: 0.0475484\n",
      "[371]\ttraining's multi_logloss: 0.0475484\n",
      "[372]\ttraining's multi_logloss: 0.0475484\n",
      "[373]\ttraining's multi_logloss: 0.0475483\n",
      "[374]\ttraining's multi_logloss: 0.0475483\n",
      "[375]\ttraining's multi_logloss: 0.0475483\n",
      "[376]\ttraining's multi_logloss: 0.0475483\n",
      "[377]\ttraining's multi_logloss: 0.0475483\n",
      "[378]\ttraining's multi_logloss: 0.0475483\n",
      "[379]\ttraining's multi_logloss: 0.0475483\n",
      "[380]\ttraining's multi_logloss: 0.0475483\n",
      "[381]\ttraining's multi_logloss: 0.0475482\n",
      "[382]\ttraining's multi_logloss: 0.0475482\n",
      "[383]\ttraining's multi_logloss: 0.0475482\n",
      "[384]\ttraining's multi_logloss: 0.0475482\n",
      "[385]\ttraining's multi_logloss: 0.0475482\n",
      "[386]\ttraining's multi_logloss: 0.0475482\n",
      "[387]\ttraining's multi_logloss: 0.0475482\n",
      "[388]\ttraining's multi_logloss: 0.0475482\n",
      "[389]\ttraining's multi_logloss: 0.0475482\n",
      "[390]\ttraining's multi_logloss: 0.0475481\n",
      "[391]\ttraining's multi_logloss: 0.0475481\n",
      "[392]\ttraining's multi_logloss: 0.0475481\n",
      "[393]\ttraining's multi_logloss: 0.0475481\n",
      "[394]\ttraining's multi_logloss: 0.0475479\n",
      "[395]\ttraining's multi_logloss: 0.0475479\n",
      "[396]\ttraining's multi_logloss: 0.0475479\n",
      "[397]\ttraining's multi_logloss: 0.0475479\n",
      "[398]\ttraining's multi_logloss: 0.0475479\n",
      "[399]\ttraining's multi_logloss: 0.0475478\n",
      "[400]\ttraining's multi_logloss: 0.0475478\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_logloss: 0.0475478\n"
     ]
    }
   ],
   "source": [
    "# LightGBM의 파이썬 패키지인 lightgbm에서 LGBMClassifier 임포트\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 앞서 XGBoost와 동일하게 n_estimators는 400 설정. \n",
    "lgbm_wrapper = LGBMClassifier(n_estimators=400)\n",
    "\n",
    "# LightGBM도 XGBoost와 동일하게 조기 중단 수행 가능. \n",
    "evals = [(X_test, y_test)]\n",
    "lgbm_wrapper.fit(X_train, y_train, early_stopping_rounds=100, eval_metric=\"logloss\", \n",
    "                 eval_set=evals, verbose=True)\n",
    "preds = lgbm_wrapper.predict(X_test)\n",
    "pred_proba = lgbm_wrapper.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['preds'] = preds\n",
    "df_copy['pred_proba'] = pred_proba\n",
    "\n",
    "df_copy2 = df_copy\n",
    "del df_copy2['X_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>C1</th>\n",
       "      <th>preds</th>\n",
       "      <th>pred_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>불량</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>레이스토어</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>글스토어</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>음</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>히어로 스카이</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47576</th>\n",
       "      <td>1</td>\n",
       "      <td>불량</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47577</th>\n",
       "      <td>1</td>\n",
       "      <td>불량</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47578</th>\n",
       "      <td>1</td>\n",
       "      <td>불량</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47579</th>\n",
       "      <td>1</td>\n",
       "      <td>불량</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47580</th>\n",
       "      <td>1</td>\n",
       "      <td>불량</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47581 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label       C1  preds  pred_proba\n",
       "0          1       불량      1    0.997583\n",
       "1          1    레이스토어      0    0.106690\n",
       "2          1     글스토어      0    0.106690\n",
       "3          1        음      0    0.106690\n",
       "4          0  히어로 스카이      0    0.106690\n",
       "...      ...      ...    ...         ...\n",
       "47576      1       불량      1    0.997583\n",
       "47577      1       불량      1    0.997583\n",
       "47578      1       불량      1    0.997583\n",
       "47579      1       불량      1    0.997583\n",
       "47580      1       불량      1    0.997583\n",
       "\n",
       "[47581 rows x 4 columns]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "#엑셀 저장\n",
    "df_copy2.to_excel('google_result_20201213.xlsx',sheet_name='result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred, pos_label='positive', average='micro')\n",
    "    recall = recall_score(y_test , pred, pos_label='positive', average='micro')\n",
    "    f1 = f1_score(y_test,pred, average='micro')\n",
    "    # ROC-AUC 추가 \n",
    "#     roc_auc = roc_auc_score(y_test, pred_proba, average='micro' , multi_class = 'ovo')\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    \n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}'.format(accuracy, precision, recall, f1))\n",
    "    \n",
    "#     # ROC-AUC print 추가\n",
    "#     print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "#     F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[45907     0     1]\n",
      " [  408    63     0]\n",
      " [  276     0   926]]\n",
      "정확도: 0.9856, 정밀도: 0.9856, 재현율: 0.9856,    F1: 0.9856\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test, preds, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot_importance( )를 이용하여 feature 중요도 시각화\n",
    "# from lightgbm import plot_importance\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 12))\n",
    "# plot_importance(lgbm_wrapper, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
